{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819aa01d",
   "metadata": {},
   "source": [
    "Classification Model Development\n",
    "\n",
    "Classification is the process of assigning a set of predefined categories or classes to a new observation or instance based on the observation's features or attributes. It is a supervised machine learning technique in which the algorithm is trained on a labeled dataset to learn relationships and patterns between input features and output classes. Once trained, the model can predict the class of previously unseen new observations (Amin et al., 2019). In that regard, classification models are machine learning models that use a set of features or attributes to predict the category or class of a given input. They are commonly used in image recognition, text classification, fraud detection, and spam filtering, among other things (Amin et al., 2019). Logistic Regression, Decision Trees (Classification Tree), Random Forests, Support Vector Machines (SVMs), Naive Bayes, and Neural Networks are some examples of classification models.\n",
    "\n",
    "The Classification Tree model is a type of decision tree algorithm used for classification tasks. It works by recursively partitioning the data into subsets based on the values of the input features, with the goal of minimizing the impurity of the resulting subsets. The model then assigns a class label to each leaf node of the resulting tree based on the majority class of the instances in that subset. A logistic regression model is typically used for binary classification problems in which the output variable has only two possible values i.e., 0 or 1, yes or No, etc. It utilizes a logistic function to model the likelihood of the output variable belonging to a particular class (Zou et al., 2019). Decision trees, on the other hand, use a tree-like structure to represent the classification decision-making process. It divides the input according to the values of its features, and each branch of the tree corresponds to a feature-based decision. The random forest model is a collection of decision trees, with each tree trained on a different set of input data and features (Hao et al., 2019). The final prediction is made by aggregating all of the trees' predictions. Gradient Boosted Machine (GBM) is a type of machine learning algorithm that combines the strengths of decision trees and boosting. GBM builds an ensemble of decision trees, where each tree is built on the errors (residuals) of the previous tree in the sequence. This way, the model learns to predict the residuals of the previous tree, rather than the original target variable.\n",
    "\n",
    "Furthermore, SVMs are used to solve both binary and multi-class classification problems. It works by finding the hyperplane that best separates the input data into different classes (Hao et al., 2019). The Naive Bayes model is based on Bayes' theorem and assumes that given the class, the features are conditionally independent. It is frequently used in text classification tasks. Finally, the Neural Networks model is a complex, non-linear model that can be applied to binary and multi-class classification problems (Hao et al., 2019). It learns features and makes predictions using multiple layers of nodes. These are just a few examples of the many different classification models that are available, and the choice of model depends on the specific problem being solved and the characteristics of the input data. In this project, we build three models i.e., Classification Tree, Random Forest, and Gradient Boosting to classify the binary response variable. We have chosen these classification models because they are known for their ability to accurately classify binary response variables. All three models have been extensively used in research and industry for binary classification tasks, making them reliable choices for our specific problem (Chen et al., 2020). By employing these algorithms, we hope to build a robust and accurate classification system that can effectively predict the binary response variable.\n",
    "\n",
    "My code performs a binary classification task on the Cross_Sell_Success_Dataset_2023.xlsx dataset using three different models: Classification Tree, Random Forest, and Gradient Boosting. The goal is to evaluate the performance of each model and choose the one with the highest area under the receiver operating characteristic curve (AUC). Here is how the code is built and how it works: The code is performing a binary classification task using three different machine learning models - Classification Tree, Random Forest, and Gradient Boosting Machine. The dataset being used is read from an Excel file and then preprocessed by performing feature engineering and encoding categorical variables using one-hot encoding. The dataset is then split into training and testing sets.\n",
    "\n",
    "The code then creates a dictionary containing the three models and their corresponding hyperparameters to be tested. Grid search is performed to identify the optimal hyperparameters for each model using cross-validation. After identifying the optimal hyperparameters, the models are trained on the training set and evaluated on the testing set using several performance metrics - Training Accuracy, Testing Accuracy, Train-Test Gap, AUC Score, and Confusion Matrix. These metrics are then stored in a results DataFrame. Finally, the best performing model based on the highest AUC Score is identified and the results DataFrame is printed out.\n",
    "\n",
    "The AUC (Area Under the Receiver Operating Characteristic Curve) score is a popular metric for assessing the performance of a binary classification model. It assesses the model's ability to distinguish between positive and negative classes (Sofaer et al., 2019). The ROC curve compares the true positive rate (TPR) to the false positive rate (FPR) for various classifier probability thresholds. The AUC score is the area under the ROC curve, which ranges from 0.0 to 1.0, with 0.5 representing a random guess and 1.0 representing perfect classification (Sofaer et al., 2019). A high AUC score indicates that the model can make distinctions between positive and negative classes well, whereas a low score indicates poor performance (Sofaer et al., 2019). The AUC score is especially useful when the class distribution is skewed, with one class outnumbering the others (Sofaer et al., 2019). In such cases, accuracy alone can be deceptive because the model can achieve high accuracy simply by predicting the majority class and ignoring the minority class.\n",
    "\n",
    "Output\n",
    "\n",
    "| Model Type                | Training Accuracy | Testing Accuracy | Train-Test Gap| AUC Score  | Confusion Matrix           \n",
    "| ------------------------- | ----------------- | ---------------- | ------------  | -----------| --------------------------|\n",
    "| Classification Tree       | 0.7756            | 0.6410           | 0.1346        | (0.5274)   | ([[13, 50], [20, 112]],)  |\n",
    "| Random Forest             | 0.7350            | 0.6667           | 0.0683        | (0.4924)   | ([[0, 63], [2, 130]],)    |\n",
    "| Gradient Boosted Machine  | 1.0000            | 0.6154           | 0.3846        | (0.4835)   | ([[7, 56], [19, 113]],)   |\n",
    "\n",
    "\n",
    "Based on the table, the Classification Tree model has the highest training accuracy of 0.7756 and the lowest testing accuracy of 0.6410. The training accuracy of the Random Forest model is 0.7350, but the testing accuracy is 0.6667. The Gradient Boosted Machine model has a perfect training accuracy of 1.0000 but the lowest testing accuracy of 0.6154.\n",
    "\n",
    "The train-test gap measures the difference between a model's training and testing accuracy, and the Gradient Boosted Machine model has the highest train-test gap of 0.3846. The AUC score measures the model's ability to distinguish between positive and negative classes, and we can see that the AUC scores for all three models are relatively low.\n",
    "\n",
    "\n",
    "Classification Tree Confusion Matrix\n",
    "|                   | Actual Positive| Actual Negative|\n",
    "|-------------------|----------------|----------------|\n",
    "| Predicted Positive|       112      |        50      |\n",
    "| Predicted Negative|       20       |        13      |\n",
    "\n",
    "True Positive (TP): Out of the total 195 instances, the model correctly predicted 112 positive cases.\n",
    "False Positive (FP): The model incorrectly predicted 50 negative cases as positive.\n",
    "True Negative (TN): The model correctly predicted 13 negative cases.\n",
    "False Negative (FN): The model incorrectly predicted 20 positive cases as negative.\n",
    "\n",
    "\n",
    "\n",
    "Random Forest\n",
    "|                   | Actual Positive| Actual Negative|\n",
    "|-------------------|----------------|----------------|\n",
    "| Predicted Positive|       130      |        63      |\n",
    "| Predicted Negative|         2      |         0      |\n",
    "\n",
    "True Positive (TP): Out of the total 195 instances, the model correctly predicted 130 positive cases.\n",
    "False Positive (FP): The model incorrectly predicted 63 negative cases as positive.\n",
    "True Negative (TN): The model correctly predicted 0 negative cases.\n",
    "False Negative (FN): The model incorrectly predicted 2 positive cases as negative.\n",
    "\n",
    "\n",
    "Gradient Boosted Machine Confusion Matrix\n",
    "|                   | Actual Positive| Actual Negative|\n",
    "|-------------------|----------------|----------------|\n",
    "| Predicted Positive|       113      |        56      |\n",
    "| Predicted Negative|        19      |         7      |\n",
    "\n",
    "True Positive (TP): Out of the total 195 instances, the model correctly predicted 113 positive cases.\n",
    "False Positive (FP): The model incorrectly predicted 56 negative cases as positive.\n",
    "True Negative (TN): The model correctly predicted 7 negative cases.\n",
    "False Negative (FN): The model incorrectly predicted 19 positive cases as negative.\n",
    "\n",
    "Summary\n",
    "\n",
    "Errors in a confusion matrix for a company trying to predict sales success can have serious consequences for the company's sales strategy and bottom line. In general, false positives (predicting a successful sale when there will not be one) can waste resources, such as time and money spent pursuing unprofitable deals, and can potentially harm the company's reputation if customers feel pressured or deceived.\n",
    "\n",
    "False negatives (failure to predict a successful sale when one is likely to occur) can result in revenue and growth opportunities being lost. If the model consistently underestimates sales success, the company may need to change its sales tactics or invest in additional marketing efforts to reach out to potential customers. As a result,  the performance of the sales prediction models should be assessed and adjusted the company's strategy as needed based on the type and frequency of errors. This can help ensure that the company's resources are being allocated effectively and that every opportunity to maximize sales success is being taken advantage of.\n",
    "\n",
    "\n",
    "References\n",
    "\n",
    "Amin, M. S., Chiam, Y. K., & Varathan, K. D. (2019). Identification of significant features and data mining techniques in predicting heart disease. Telematics and Informatics, 36, 82-93. Chen, R. C., Dewi, C., Huang, S. W., & Caraka, R. E. (2020). Selecting critical features for data classification based on machine learning methods. Journal of Big Data, 7(1), 52. Choudhury, S. J., & Pal, N. R. (2019). Imputation of missing data with neural networks for classification. Knowledge-Based Systems, 182, 104838. Hao, J., & Ho, T. K. (2019). Machine learning made easy: a review of scikit-learn package in python programming language. Journal of Educational and Behavioral Statistics, 44(3), 348-361. Nguyen, G., Dlugolinsky, S., Bobák, M., Tran, V., López García, Á., Heredia, I., ... & Hluchý, L. (2019). Machine learning and deep learning frameworks and libraries for large-scale data mining: a survey. Artificial Intelligence Review, 52, 77-124. Sofaer, H. R., Hoeting, J. A., & Jarnevich, C. S. (2019). The area under the precision‐recall curve as a performance metric for rare binary events. Methods in Ecology and Evolution, 10(4), 565-577. Zou, X., Hu, Y., Tian, Z., & Shen, K. (2019, October). Logistic regression model optimization and case analysis. In 2019 IEEE 7th international conference on computer science and network technology (ICCSNT) (pp. 135-139). IEEE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "420edfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model: \n",
      "                 Model Type  Training Accuracy  Testing Accuracy  \\\n",
      "0       Classification Tree             0.7756            0.6410   \n",
      "1             Random Forest             0.7350            0.6667   \n",
      "2  Gradient Boosted Machine             1.0000            0.6154   \n",
      "\n",
      "   Train-Test Gap               AUC Score          Confusion Matrix  \n",
      "0          0.1346   (0.5274170274170275,)  ([[13, 50], [20, 112]],)  \n",
      "1          0.0683  (0.49242424242424243,)    ([[0, 63], [2, 130]],)  \n",
      "2          0.3846   (0.4835858585858586,)   ([[7, 56], [19, 113]],)  \n"
     ]
    }
   ],
   "source": [
    "# importig necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# reading in the data\n",
    "file = 'C:\\\\Users\\\\User\\\\Desktop\\\\Cross_Sell_Success_Dataset_2023.xlsx'\n",
    "original_df = pd.read_excel(file)\n",
    "# removing leading/trailing whitespaces from column names\n",
    "original_df.columns = original_df.columns.to_series().apply(lambda x: x.strip())\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# setting seed and define target variable\n",
    "np.random.seed(219)\n",
    "target_var = 'CROSS_SELL_SUCCESS'\n",
    "# performing feature engineering\n",
    "original_df['log_REVENUE'] = np.log(original_df['REVENUE'])\n",
    "original_df['log_AVG_TIME_PER_SITE_VISIT'] = np.log(original_df['AVG_TIME_PER_SITE_VISIT'])\n",
    "original_df['log_AVG_PREP_VID_TIME'] = np.log(original_df['AVG_PREP_VID_TIME'])\n",
    "# selecting all relevant independent variables and split into train/test sets\n",
    "x_variables = ['log_REVENUE', 'TOTAL_MEALS_ORDERED', 'UNIQUE_MEALS_PURCH',\n",
    "               'CONTACTS_W_CUSTOMER_SERVICE', 'PRODUCT_CATEGORIES_VIEWED',\n",
    "               'log_AVG_TIME_PER_SITE_VISIT', 'CANCELLATIONS_AFTER_NOON',\n",
    "               'PC_LOGINS', 'MOBILE_LOGINS', 'WEEKLY_PLAN','LATE_DELIVERIES',\n",
    "               'log_AVG_PREP_VID_TIME', 'LARGEST_ORDER_SIZE', 'AVG_MEAN_RATING',\n",
    "               'TOTAL_PHOTOS_VIEWED']\n",
    "\n",
    "# identify categorical variables\n",
    "cat_vars = ['PRODUCT_CATEGORIES_VIEWED']\n",
    "# remove one category from each categorical variable\n",
    "for cat_var in cat_vars:\n",
    "    categories = original_df[cat_var].unique()\n",
    "    if len(categories) > 1:\n",
    "        original_df[cat_var] = original_df[cat_var].apply(lambda x: np.random.choice(categories[:-1]) if x == categories[-1] else x)\n",
    "# encode categorical variables using one-hot encoding\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "X_cat = encoder.fit_transform(original_df[cat_vars]).toarray()\n",
    "X_cat_df = pd.DataFrame(X_cat, columns=encoder.get_feature_names(cat_vars))\n",
    "X = original_df[x_variables].join(X_cat_df)\n",
    "y = original_df.loc[:, target_var]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.10,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 219)\n",
    "\n",
    "# creating model dictionary with hyperparameters to test\n",
    "model_dict = {'Classification Tree': DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                            max_depth = 8,\n",
    "                                                            random_state = 219),\n",
    "              'Random Forest': RandomForestClassifier(criterion = 'gini',\n",
    "                                                      max_depth = 8,\n",
    "                                                      random_state = 219),\n",
    "              'Gradient Boosted Machine': GradientBoostingClassifier(loss = 'deviance',\n",
    "                                                                     learning_rate = 0.1,\n",
    "                                                                     n_estimators = 100,\n",
    "                                                                     max_depth = 8,\n",
    "                                                                     random_state = 219)}\n",
    "# performing grid search to identify optimal hyperparameters for each model\n",
    "for model_name in model_dict.keys():\n",
    "    model = GridSearchCV(estimator = model_dict[model_name],\n",
    "                         param_grid = {},\n",
    "                         cv = 5,\n",
    "                         scoring = 'roc_auc',\n",
    "                         refit = True,\n",
    "                         n_jobs = -1)\n",
    "    model.fit(X_train, y_train)\n",
    "    model_dict[model_name] = model.best_estimator_\n",
    "# evaluating model performance on train/test sets and output results\n",
    "final_model_name = ''\n",
    "results_df = pd.DataFrame(columns = ['Model Type', 'Training Accuracy', 'Testing Accuracy', \n",
    "                                     'Train-Test Gap', 'AUC Score', 'Confusion Matrix'])\n",
    "for model_name in model_dict.keys():\n",
    "    model = model_dict[model_name]\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    train_acc = round(accuracy_score(y_train, y_train_pred), 4)\n",
    "    test_acc = round(accuracy_score(y_test, y_test_pred), 4)\n",
    "    train_test_gap = round(abs(train_acc - test_acc), 4)\n",
    "    auc = roc_auc_score(y_test, y_test_pred), \n",
    "    cm = confusion_matrix(y_test, y_test_pred),\n",
    "    results_df = results_df.append({'Model Type': model_name,\n",
    "'Training Accuracy': train_acc,\n",
    "'Testing Accuracy': test_acc,\n",
    "'Train-Test Gap': train_test_gap,\n",
    "'AUC Score': auc,\n",
    "'Confusion Matrix': cm}, ignore_index=True)\n",
    "if auc > results_df['AUC Score'].max():\n",
    "    final_model_name = model_name\n",
    "print(f\"Best performing model: {final_model_name}\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b1588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
